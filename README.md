# ğŸš€ Automated UML Activity Diagram Generation using LLMs

This research project explores a prompt-based pipeline for automatically generating **UML Activity Diagrams** from natural language requirements using **Large Language Models (LLMs)**.

> ğŸ“… *Minor Research Project â€” M.Tech (Janâ€“May 2025)*  
> ğŸ‘¨â€ğŸ« *Mentor: Saurabh Tiwari*  
> ğŸ§‘â€ğŸ’» *Author: Vrajkumar Patel*

---

## ğŸ“Œ Project Overview

Manually creating UML Activity Diagrams is time-consuming, error-prone, and requires domain expertise. This project presents a **model-agnostic pipeline** that combines:

- **Chain-of-Thought prompting** for structured reasoning
- **ClarifyGPT-style refinement** using an Evaluator LLM
- **PlantUML script generation** for visual output
- **Quantitative and qualitative evaluation** for measuring improvement

---

## ğŸ› ï¸ Tech Stack

- ğŸ§  Large Language Models: Gemini 1.5 Flash, LLaMA 3.2  
- ğŸ§ª Prompt Engineering: Chain-of-Thought (CoT), ClarifyGPT-style evaluation  
- ğŸ–‹ï¸ Scripting & IDEs: Python, Jupyter Notebook, VS Code  
- ğŸ“Š Evaluation: Manual scoring, t-test statistical analysis  
- ğŸ¨ Diagram Rendering: PlantUML  
- ğŸ§ª Experiment Tools: RStudio, Ollama, Git  

---

## ğŸ”„ Workflow

1. **Input**: Natural Language problem statement  
2. **LLM Processing**:
   - Action & control flow extraction (via CoT)
   - Initial diagram generation (PlantUML script)  
3. **Evaluator Loop**:
   - LLaMA 3.2 generates clarifying questions  
   - Responses used to regenerate a refined diagram  
4. **Output**:
   - Final refined diagram with improved correctness and completeness  
5. **Evaluation**:
   - Scored across 5 dimensions: Completeness, Correctness, Standards, Terminology, Understandability

---

## ğŸ“ˆ Results Summary

| Metric              | Before (Mean) | After (Mean) | % Improvement | Significance |
|---------------------|----------------|---------------|----------------|---------------|
| Completeness        | 2.2            | 3.6           | +63.6%         | âœ… Significant |
| Correctness         | 3.0            | 4.0           | +33.3%         | âœ… Significant |
| Standards Adherence | 4.6            | 5.0           | +8.7%          | âŒ Not Sig.    |
| Understandability   | 3.6            | 4.2           | +16.7%         | âŒ Not Sig.    |
| Terminology         | 4.8            | 5.0           | +4.2%          | âŒ Not Sig.    |

---

## ğŸ“‚ Folder Structure

```bash
â”œâ”€â”€ notebooks/          # Jupyter notebooks for generation and evaluation
â”œâ”€â”€ prompts/            # CoT and ClarifyGPT prompt templates
â”œâ”€â”€ diagrams/           # Generated PlantUML diagrams
â”œâ”€â”€ data/               # Problem statements and annotations
â”œâ”€â”€ results/            # Metrics, charts, evaluation tables
â””â”€â”€ README.md
