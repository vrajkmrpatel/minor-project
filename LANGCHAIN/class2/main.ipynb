{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-ollama in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-ollama) (0.3.43)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-ollama) (0.4.7)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.3.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.10.6)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ollama<1,>=0.4.4->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (3.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.0.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (2023.7.22)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.31.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.10.15)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.0.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# using ollama\n",
    "%pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.schema import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_statement = \"\"\"Metro station wants to establish a TicketDistributor machine that issues tickets for\n",
    "passengers travelling on metro rails. Travellers have options of selecting a ticket for a single\n",
    "trip, round trips or multiple trips. They can also issue a metro pass for regular passengers or\n",
    "a time card for a day, a week or a month according to their requirements. The discounts on\n",
    "tickets will be provided to frequent travelling passengers. The machine is also supposed to\n",
    "read the metro pass and time cards issued by the metro counters or machine. The ticket rates\n",
    "differ based on whether the traveller is a child or an adult. The machine is also required to\n",
    "recognize original as well as fake currency notes. The typical transaction consists of a user\n",
    "using the display interface to select the type and quantity of tickets and then choosing a\n",
    "payment method of either cash, credit/debit card or smartcard. The tickets are printed and\n",
    "dispensed to the user. Also, the messaging facilities after every transaction are required on\n",
    "the registered number. The system can also be operated comfortably by a touch-screen. A\n",
    "large number of heavy components are to be used. We do not want our system to slow down,\n",
    "and also the usability of the machine.\n",
    "The TicketDistributor must be able to handle several exceptions, such as aborting the\n",
    "transaction for incomplete transactions, the insufficient amount given by the travellers to the\n",
    "machine, money return in case of an aborted transaction, change return after a successful\n",
    "transaction, showing insufficient balance in the card, updated information printed on the\n",
    "tickets e.g. departure time, date, time, price, valid from, valid till, validity duration, ticket\n",
    "issued from and destination station. In case of exceptions, an error message is to be displayed.\n",
    "We do not want user feedback after every development stage but after every two stages to\n",
    "save time. The machine is required to work in a heavy load environment such that in the\n",
    "morning and evening time on weekdays, and weekends performance and efficiency would\n",
    "not be affected.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Response from LLaMA 3.2:\n",
      " {\n",
      "  \"classes\": [\n",
      "    \"MetroStation\",\n",
      "    \"TicketDistributor\",\n",
      "    \"Traveller\",\n",
      "    \"Passenger\",\n",
      "    \"Child\",\n",
      "    \"Adult\",\n",
      "    \"MetroPass\",\n",
      "    \"TimeCard\",\n",
      "    \"Transaction\",\n",
      "    \"User\",\n",
      "    \"Machine\",\n",
      "    \"CurrencyNote\"\n",
      "  ]\n",
      "}\n",
      "Cleaned JSON:\n",
      " '{\\n  \"classes\": [\\n    \"MetroStation\",\\n    \"TicketDistributor\",\\n    \"Traveller\",\\n    \"Passenger\",\\n    \"Child\",\\n    \"Adult\",\\n    \"MetroPass\",\\n    \"TimeCard\",\\n    \"Transaction\",\\n    \"User\",\\n    \"Machine\",\\n    \"CurrencyNote\"\\n  ]\\n}'\n",
      "Identified Classes: ['MetroStation', 'TicketDistributor', 'Traveller', 'Passenger', 'Child', 'Adult', 'MetroPass', 'TimeCard', 'Transaction', 'User', 'Machine', 'CurrencyNote']\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "\n",
    "def identify_classes(problem_statement):\n",
    "    \"\"\"\n",
    "    Identifies potential class names from a given problem statement using Ollama LLaMA 3.2.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert software analyst. Your task is to extract potential class names from a given problem statement. \n",
    "    Follow this step-by-step approach:\n",
    "\n",
    "    1. Identify the key **nouns** representing domain concepts.\n",
    "    2. If a noun represents a role or system entity, classify it as a **class**.\n",
    "    3. Ignore verbs and adjectives.\n",
    "    4. **Output only valid JSON** in the following format without any explanation:\n",
    "       {{\n",
    "           \"classes\": [\"Class1\", \"Class2\", \"Class3\"]\n",
    "       }}\n",
    "\n",
    "    **Problem Statement:**\n",
    "    {problem_statement}\n",
    "\n",
    "    Now extract the class names based on the above rules.  \n",
    "    **Do NOT include any explanation — output JSON only.**\n",
    "    \"\"\"\n",
    "      \n",
    "    # Generate response using Ollama LLaMA 3.2\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        options={\n",
    "            \"temperature\": 0,\n",
    "            \"top_p\": 1,\n",
    "            \"top_k\": 1\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Debugging: Print raw response\n",
    "    response_text = response['message']['content'].strip()\n",
    "    print(\"Raw Response from LLaMA 3.2:\\n\", response_text)\n",
    "\n",
    "    # ✅ Extract JSON part only using regex\n",
    "    json_match = re.search(r\"\\{.*\\}\", response_text, re.DOTALL)\n",
    "    if json_match:\n",
    "        cleaned_text = json_match.group(0).strip()\n",
    "    else:\n",
    "        print(\"Error: No valid JSON found in response.\")\n",
    "        return []\n",
    "\n",
    "    # Additional Debugging: Print cleaned text before parsing\n",
    "    print(\"Cleaned JSON:\\n\", repr(cleaned_text))\n",
    "\n",
    "    # ✅ Check if cleaned_text is empty\n",
    "    if not cleaned_text:\n",
    "        print(\"Error: Cleaned JSON is empty. Cannot parse.\")\n",
    "        return []\n",
    "\n",
    "    # ✅ Parse JSON safely\n",
    "    try:\n",
    "        output = json.loads(cleaned_text)  # Convert string to JSON\n",
    "        return output.get(\"classes\", [])  # Ensure output is a list\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"JSON parsing error:\", str(e))\n",
    "        return []\n",
    "\n",
    "identified_classes = identify_classes(problem_statement)\n",
    "print(\"Identified Classes:\", identified_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Response from LLaMA 3.2:\n",
      " {\n",
      "  \"attributes\": {\n",
      "    \"MetroStation\": [\"ID\", \"name\"],\n",
      "    \"TicketDistributor\": [\"ID\", \"type\", \"status\", \"capacity\"],\n",
      "    \"Traveller\": [\"ID\", \"age\", \"type\"],\n",
      "    \"Passenger\": [\"ID\", \"type\"],\n",
      "    \"Child\": [\"ID\", \"type\"],\n",
      "    \"Adult\": [\"ID\", \"type\"],\n",
      "    \"MetroPass\": [\"ID\", \"type\", \"duration\"],\n",
      "    \"TimeCard\": [\"ID\", \"type\", \"duration\"],\n",
      "    \"Transaction\": [\"ID\", \"status\", \"amount\"],\n",
      "    \"User\": [\"ID\", \"name\", \"registered_number\"],\n",
      "    \"Machine\": [\"ID\", \"type\", \"load_environment\"],\n",
      "    \"DisplayInterface\": [\"ID\", \"type\"],\n",
      "    \"PaymentMethod\": [\"ID\", \"type\"],\n",
      "    \"Smartcard\": [\"ID\", \"type\"],\n",
      "    \"CurrencyNote\": [\"ID\", \"type\"],\n",
      "    \"TouchScreen\": [\"ID\", \"type\"]\n",
      "  }\n",
      "}\n",
      "Cleaned JSON:\n",
      " '{\\n  \"attributes\": {\\n    \"MetroStation\": [\"ID\", \"name\"],\\n    \"TicketDistributor\": [\"ID\", \"type\", \"status\", \"capacity\"],\\n    \"Traveller\": [\"ID\", \"age\", \"type\"],\\n    \"Passenger\": [\"ID\", \"type\"],\\n    \"Child\": [\"ID\", \"type\"],\\n    \"Adult\": [\"ID\", \"type\"],\\n    \"MetroPass\": [\"ID\", \"type\", \"duration\"],\\n    \"TimeCard\": [\"ID\", \"type\", \"duration\"],\\n    \"Transaction\": [\"ID\", \"status\", \"amount\"],\\n    \"User\": [\"ID\", \"name\", \"registered_number\"],\\n    \"Machine\": [\"ID\", \"type\", \"load_environment\"],\\n    \"DisplayInterface\": [\"ID\", \"type\"],\\n    \"PaymentMethod\": [\"ID\", \"type\"],\\n    \"Smartcard\": [\"ID\", \"type\"],\\n    \"CurrencyNote\": [\"ID\", \"type\"],\\n    \"TouchScreen\": [\"ID\", \"type\"]\\n  }\\n}'\n",
      "\n",
      "Extracted Attributes:\n",
      " {'MetroStation': ['ID', 'name'], 'TicketDistributor': ['ID', 'type', 'status', 'capacity'], 'Traveller': ['ID', 'age', 'type'], 'Passenger': ['ID', 'type'], 'Child': ['ID', 'type'], 'Adult': ['ID', 'type'], 'MetroPass': ['ID', 'type', 'duration'], 'TimeCard': ['ID', 'type', 'duration'], 'Transaction': ['ID', 'status', 'amount'], 'User': ['ID', 'name', 'registered_number'], 'Machine': ['ID', 'type', 'load_environment'], 'DisplayInterface': ['ID', 'type'], 'PaymentMethod': ['ID', 'type'], 'Smartcard': ['ID', 'type'], 'CurrencyNote': ['ID', 'type'], 'TouchScreen': ['ID', 'type']}\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "\n",
    "def identify_attributes(problem_statement, classes):\n",
    "    \"\"\"\n",
    "    Identifies attributes for each class extracted from the problem statement using Ollama LLaMA 3.2.\n",
    "    Ensures deterministic output and structured JSON format.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert software analyst. Your task is to extract **attributes** for each identified class from the given problem statement.\n",
    "\n",
    "    **Rules to Identify Attributes:**\n",
    "    1. Attributes describe **properties or characteristics** of a class.\n",
    "    2. Ignore verbs, complex entities, and relationships.\n",
    "    3. Common attributes include **names, IDs, types, and statuses**.\n",
    "    4. **Output ONLY valid JSON** in the following format (without any explanation):\n",
    "       {{\n",
    "           \"attributes\": {{\n",
    "               \"Class1\": [\"attribute1\", \"attribute2\"],\n",
    "               \"Class2\": [\"attribute1\", \"attribute2\"]\n",
    "           }}\n",
    "       }}\n",
    "\n",
    "    **Classes Identified:**\n",
    "    {classes}\n",
    "\n",
    "    **Problem Statement:**\n",
    "    {problem_statement}\n",
    "\n",
    "    Now extract the attributes for each class.\n",
    "    **Do NOT include any explanation — output JSON only.**\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate response using Ollama LLaMA 3.2\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        options={\n",
    "            \"temperature\": 0,\n",
    "            \"top_p\": 1,\n",
    "            \"top_k\": 1\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # ✅ Debugging: Print raw response\n",
    "    response_text = response['message']['content'].strip()\n",
    "    print(\"Raw Response from LLaMA 3.2:\\n\", response_text)\n",
    "\n",
    "    # ✅ Extract JSON part only using regex\n",
    "    json_match = re.search(r\"\\{.*\\}\", response_text, re.DOTALL)\n",
    "    if json_match:\n",
    "        cleaned_text = json_match.group(0).strip()\n",
    "    else:\n",
    "        print(\"Error: No valid JSON found in response.\")\n",
    "        return {}\n",
    "\n",
    "    # ✅ Additional Debugging: Print cleaned text before parsing\n",
    "    print(\"Cleaned JSON:\\n\", repr(cleaned_text))\n",
    "\n",
    "    # ✅ Check if cleaned_text is empty\n",
    "    if not cleaned_text:\n",
    "        print(\"Error: Cleaned JSON is empty. Cannot parse.\")\n",
    "        return {}\n",
    "\n",
    "    # ✅ Parse JSON safely\n",
    "    try:\n",
    "        output = json.loads(cleaned_text)  # Convert string to JSON\n",
    "        return output.get(\"attributes\", {})  # Extract attributes dictionary\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"JSON parsing error:\", str(e))\n",
    "        return {}\n",
    "\n",
    "identified_attributes = identify_attributes(problem_statement, identified_classes)\n",
    "\n",
    "print(\"\\nExtracted Attributes:\\n\", identified_attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Response from LLaMA 3.2:\n",
      " {\n",
      "  \"relationships\": [\n",
      "    {\"source\": \"MetroStation\", \"target\": \"TicketDistributor\", \"type\": \"Aggregation\", \"description\": \"Metro station contains TicketDistributor\"},\n",
      "    {\"source\": \"Traveller\", \"target\": \"Passenger\", \"type\": \"Generalization\", \"description\": \"Traveller is a subclass of Passenger\"},\n",
      "    {\"source\": \"Child\", \"target\": \"Adult\", \"type\": \"Generalization\", \"description\": \"Child is a subclass of Adult\"},\n",
      "    {\"source\": \"TicketDistributor\", \"target\": \"MetroPass\", \"type\": \"Aggregation\", \"description\": \"TicketDistributor contains MetroPass\"},\n",
      "    {\"source\": \"TicketDistributor\", \"target\": \"TimeCard\", \"type\": \"Aggregation\", \"description\": \"TicketDistributor contains TimeCard\"},\n",
      "    {\"source\": \"User\", \"target\": \"Machine\", \"type\": \"Aggregation\", \"description\": \"User contains Machine\"},\n",
      "    {\"source\": \"Machine\", \"target\": \"DisplayInterface\", \"type\": \"Aggregation\", \"description\": \"Machine contains DisplayInterface\"},\n",
      "    {\"source\": \"PaymentMethod\", \"target\": \"Smartcard\", \"type\": \"Generalization\", \"description\": \"PaymentMethod is a subclass of Smartcard\"},\n",
      "    {\"source\": \"PaymentMethod\", \"target\": \"CurrencyNote\", \"type\": \"Generalization\", \"description\": \"PaymentMethod is a subclass of CurrencyNote\"}\n",
      "  ]\n",
      "}\n",
      "Cleaned JSON:\n",
      " '{\\n  \"relationships\": [\\n    {\"source\": \"MetroStation\", \"target\": \"TicketDistributor\", \"type\": \"Aggregation\", \"description\": \"Metro station contains TicketDistributor\"},\\n    {\"source\": \"Traveller\", \"target\": \"Passenger\", \"type\": \"Generalization\", \"description\": \"Traveller is a subclass of Passenger\"},\\n    {\"source\": \"Child\", \"target\": \"Adult\", \"type\": \"Generalization\", \"description\": \"Child is a subclass of Adult\"},\\n    {\"source\": \"TicketDistributor\", \"target\": \"MetroPass\", \"type\": \"Aggregation\", \"description\": \"TicketDistributor contains MetroPass\"},\\n    {\"source\": \"TicketDistributor\", \"target\": \"TimeCard\", \"type\": \"Aggregation\", \"description\": \"TicketDistributor contains TimeCard\"},\\n    {\"source\": \"User\", \"target\": \"Machine\", \"type\": \"Aggregation\", \"description\": \"User contains Machine\"},\\n    {\"source\": \"Machine\", \"target\": \"DisplayInterface\", \"type\": \"Aggregation\", \"description\": \"Machine contains DisplayInterface\"},\\n    {\"source\": \"PaymentMethod\", \"target\": \"Smartcard\", \"type\": \"Generalization\", \"description\": \"PaymentMethod is a subclass of Smartcard\"},\\n    {\"source\": \"PaymentMethod\", \"target\": \"CurrencyNote\", \"type\": \"Generalization\", \"description\": \"PaymentMethod is a subclass of CurrencyNote\"}\\n  ]\\n}'\n",
      "\n",
      "Relationships Identified:\n",
      " [{'source': 'MetroStation', 'target': 'TicketDistributor', 'type': 'Aggregation', 'description': 'Metro station contains TicketDistributor'}, {'source': 'Traveller', 'target': 'Passenger', 'type': 'Generalization', 'description': 'Traveller is a subclass of Passenger'}, {'source': 'Child', 'target': 'Adult', 'type': 'Generalization', 'description': 'Child is a subclass of Adult'}, {'source': 'TicketDistributor', 'target': 'MetroPass', 'type': 'Aggregation', 'description': 'TicketDistributor contains MetroPass'}, {'source': 'TicketDistributor', 'target': 'TimeCard', 'type': 'Aggregation', 'description': 'TicketDistributor contains TimeCard'}, {'source': 'User', 'target': 'Machine', 'type': 'Aggregation', 'description': 'User contains Machine'}, {'source': 'Machine', 'target': 'DisplayInterface', 'type': 'Aggregation', 'description': 'Machine contains DisplayInterface'}, {'source': 'PaymentMethod', 'target': 'Smartcard', 'type': 'Generalization', 'description': 'PaymentMethod is a subclass of Smartcard'}, {'source': 'PaymentMethod', 'target': 'CurrencyNote', 'type': 'Generalization', 'description': 'PaymentMethod is a subclass of CurrencyNote'}]\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "\n",
    "def identify_relationships(problem_statement, classes, attributes):\n",
    "    \"\"\"\n",
    "    Identifies relationships between extracted classes using Ollama LLaMA 3.2.\n",
    "    Extracts Association, Generalization (Inheritance), Aggregation, and Composition.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert software analyst. Your task is to identify **all types of relationships** between the given classes based on the problem statement.\n",
    "\n",
    "    **Types of Relationships:**\n",
    "    1️⃣ **Association** - One class interacts with another. Example: \"User borrows Book\".\n",
    "    2️⃣ **Generalization (Inheritance)** - One class is a specialized form of another. Example: \"Admin is a subclass of User\".\n",
    "    3️⃣ **Aggregation** - One class is made up of another, but they have independent lifecycles. Example: \"Library has Books, but Books exist independently\".\n",
    "    4️⃣ **Composition** - A stronger form of Aggregation, where the part **cannot exist** without the whole. Example: \"House has Rooms, Rooms cannot exist without a House\".\n",
    "\n",
    "    **Rules:**\n",
    "    - Identify the **verbs** and **context clues** in the problem statement to find relationships.\n",
    "    - Classify the relationship into one of the four types above.\n",
    "    - **Output ONLY valid JSON** in the following format (without any explanation):\n",
    "      {{\n",
    "          \"relationships\": [\n",
    "              {{\"source\": \"ClassA\", \"target\": \"ClassB\", \"type\": \"Generalization\", \"description\": \"ClassA is a subclass of ClassB\"}},\n",
    "              {{\"source\": \"ClassC\", \"target\": \"ClassD\", \"type\": \"Aggregation\", \"description\": \"ClassC contains ClassD but ClassD can exist independently\"}},\n",
    "              {{\"source\": \"ClassE\", \"target\": \"ClassF\", \"type\": \"Composition\", \"description\": \"ClassE owns ClassF and ClassF cannot exist without ClassE\"}}\n",
    "          ]\n",
    "      }}\n",
    "\n",
    "    **Classes Identified:**\n",
    "    {classes}\n",
    "\n",
    "    **Attributes Identified:**\n",
    "    {attributes}\n",
    "\n",
    "    **Problem Statement:**\n",
    "    {problem_statement}\n",
    "\n",
    "    Now extract **all types of relationships** between the classes.\n",
    "    **Do NOT include any explanation — output JSON only.**\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate response using Ollama LLaMA 3.2\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        options={\n",
    "            \"temperature\": 0,\n",
    "            \"top_p\": 1,\n",
    "            \"top_k\": 1\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ✅ Debugging: Print raw response\n",
    "    response_text = response['message']['content'].strip()\n",
    "    print(\"Raw Response from LLaMA 3.2:\\n\", response_text)\n",
    "\n",
    "    # ✅ Extract JSON part only using regex\n",
    "    json_match = re.search(r\"\\{.*\\}\", response_text, re.DOTALL)\n",
    "    if json_match:\n",
    "        cleaned_text = json_match.group(0).strip()\n",
    "    else:\n",
    "        print(\"Error: No valid JSON found in response.\")\n",
    "        return {}\n",
    "\n",
    "    # ✅ Additional Debugging: Print cleaned text before parsing\n",
    "    print(\"Cleaned JSON:\\n\", repr(cleaned_text))\n",
    "\n",
    "    # ✅ Check if cleaned_text is empty\n",
    "    if not cleaned_text:\n",
    "        print(\"Error: Cleaned JSON is empty. Cannot parse.\")\n",
    "        return {}\n",
    "\n",
    "    # ✅ Parse JSON safely\n",
    "    try:\n",
    "        output = json.loads(cleaned_text)  # Convert string to JSON\n",
    "        return output.get(\"relationships\", [])  # Extract relationships list\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"JSON parsing error:\", str(e))\n",
    "        return {}\n",
    "\n",
    "\n",
    "identified_relationships = identify_relationships(problem_statement, identified_classes, identified_attributes)\n",
    "\n",
    "print(\"\\nRelationships Identified:\\n\", identified_relationships)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes Extracted: ['MetroStation', 'TicketDistributor', 'Traveller', 'Passenger', 'Child', 'Adult', 'MetroPass', 'TimeCard', 'Transaction', 'User', 'Machine', 'CurrencyNote']\n",
      "Attributes Extracted: {'MetroStation': ['ID', 'name'], 'TicketDistributor': ['ID', 'type', 'status', 'capacity'], 'Traveller': ['ID', 'age', 'type'], 'Passenger': ['ID', 'type'], 'Child': ['ID', 'type'], 'Adult': ['ID', 'type'], 'MetroPass': ['ID', 'type', 'duration'], 'TimeCard': ['ID', 'type', 'duration'], 'Transaction': ['ID', 'status', 'amount'], 'User': ['ID', 'name', 'registered_number'], 'Machine': ['ID', 'type', 'load_environment'], 'DisplayInterface': ['ID', 'type'], 'PaymentMethod': ['ID', 'type'], 'Smartcard': ['ID', 'type'], 'CurrencyNote': ['ID', 'type'], 'TouchScreen': ['ID', 'type']}\n",
      "Relationships Extracted: [{'source': 'MetroStation', 'target': 'TicketDistributor', 'type': 'Association', 'description': 'issues'}, {'source': 'Traveller', 'target': 'Passenger', 'type': 'Aggregation', 'description': 'contains'}, {'source': 'User', 'target': 'Transaction', 'type': 'Association', 'description': 'issues'}, {'source': 'Machine', 'target': 'DisplayInterface', 'type': 'Aggregation', 'description': 'contains'}, {'source': 'PaymentMethod', 'target': 'Smartcard', 'type': 'Composition', 'description': 'is-a'}, {'source': 'MetroPass', 'target': 'TimeCard', 'type': 'Aggregation', 'description': 'contains'}, {'source': 'TicketDistributor', 'target': 'User', 'type': 'Association', 'description': 'issues'}, {'source': 'Traveller', 'target': 'Child', 'type': 'Composition', 'description': 'is-a'}, {'source': 'Traveller', 'target': 'Adult', 'type': 'Composition', 'description': 'is-a'}, {'source': 'MetroStation', 'target': 'CurrencyNote', 'type': 'Association', 'description': 'issues'}]\n",
      "PlantUML file 'class_diagram.puml' generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def generate_plantuml(classes, attributes, relationships, output_file=\"class_diagram.puml\"):\n",
    "    \"\"\"\n",
    "    Generates a PlantUML class diagram from identified classes, attributes, and relationships.\n",
    "    \"\"\"\n",
    "    plantuml_code = \"@startuml\\n\\n\"\n",
    "\n",
    "    # ✅ Define Classes and Attributes\n",
    "    for cls in classes:\n",
    "        plantuml_code += f\"class {cls} {{\\n\"\n",
    "        if cls in attributes:\n",
    "            for attr in attributes[cls]:\n",
    "                plantuml_code += f\"  {attr}\\n\"\n",
    "        plantuml_code += \"}\\n\\n\"\n",
    "\n",
    "    # ✅ Define Relationships (Simplified Labels)\n",
    "    for rel in relationships:\n",
    "        source = rel[\"source\"]\n",
    "        target = rel[\"target\"]\n",
    "        rel_type = rel[\"type\"]\n",
    "\n",
    "        # Simplified behavior labels\n",
    "        if rel_type == \"Association\":\n",
    "            plantuml_code += f\"{source} --> {target} : uses\\n\"\n",
    "        elif rel_type == \"Generalization\":\n",
    "            plantuml_code += f\"{source} --|> {target} : inherits\\n\"\n",
    "        elif rel_type == \"Aggregation\":\n",
    "            plantuml_code += f\"{source} o-- {target} : has\\n\"\n",
    "        elif rel_type == \"Composition\":\n",
    "            plantuml_code += f\"{source} *-- {target} : owns\\n\"\n",
    "\n",
    "    plantuml_code += \"\\n@enduml\"\n",
    "\n",
    "    # ✅ Save to file\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(plantuml_code)\n",
    "\n",
    "    print(f\"PlantUML file '{output_file}' generated successfully.\")\n",
    "\n",
    "\n",
    "# ✅ Debugging Check\n",
    "print(\"Classes Extracted:\", identified_classes)\n",
    "print(\"Attributes Extracted:\", identified_attributes)\n",
    "print(\"Relationships Extracted:\", identified_relationships)\n",
    "\n",
    "# ✅ Generate UML\n",
    "generate_plantuml(identified_classes, identified_attributes, identified_relationships)\n",
    "\n",
    "# 🖥️ To render, use: `plantuml class_diagram.puml` in the terminal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Response from LLaMA 3.2:\n",
      " {\n",
      "  \"relationships\": [\n",
      "    {\"source\": \"MetroStation\", \"target\": \"TicketDistributor\", \"type\": \"Association\", \"description\": \"issues\"},\n",
      "    {\"source\": \"Traveller\", \"target\": \"Passenger\", \"type\": \"Aggregation\", \"description\": \"contains\"},\n",
      "    {\"source\": \"User\", \"target\": \"Transaction\", \"type\": \"Association\", \"description\": \"issues\"},\n",
      "    {\"source\": \"Machine\", \"target\": \"DisplayInterface\", \"type\": \"Aggregation\", \"description\": \"contains\"},\n",
      "    {\"source\": \"PaymentMethod\", \"target\": \"Smartcard\", \"type\": \"Composition\", \"description\": \"is-a\"},\n",
      "    {\"source\": \"MetroPass\", \"target\": \"TimeCard\", \"type\": \"Aggregation\", \"description\": \"contains\"},\n",
      "    {\"source\": \"TicketDistributor\", \"target\": \"User\", \"type\": \"Association\", \"description\": \"issues\"},\n",
      "    {\"source\": \"Traveller\", \"target\": \"Child\", \"type\": \"Composition\", \"description\": \"is-a\"},\n",
      "    {\"source\": \"Traveller\", \"target\": \"Adult\", \"type\": \"Composition\", \"description\": \"is-a\"},\n",
      "    {\"source\": \"MetroStation\", \"target\": \"CurrencyNote\", \"type\": \"Association\", \"description\": \"issues\"}\n",
      "  ]\n",
      "}\n",
      "Cleaned JSON:\n",
      " '{\\n  \"relationships\": [\\n    {\"source\": \"MetroStation\", \"target\": \"TicketDistributor\", \"type\": \"Association\", \"description\": \"issues\"},\\n    {\"source\": \"Traveller\", \"target\": \"Passenger\", \"type\": \"Aggregation\", \"description\": \"contains\"},\\n    {\"source\": \"User\", \"target\": \"Transaction\", \"type\": \"Association\", \"description\": \"issues\"},\\n    {\"source\": \"Machine\", \"target\": \"DisplayInterface\", \"type\": \"Aggregation\", \"description\": \"contains\"},\\n    {\"source\": \"PaymentMethod\", \"target\": \"Smartcard\", \"type\": \"Composition\", \"description\": \"is-a\"},\\n    {\"source\": \"MetroPass\", \"target\": \"TimeCard\", \"type\": \"Aggregation\", \"description\": \"contains\"},\\n    {\"source\": \"TicketDistributor\", \"target\": \"User\", \"type\": \"Association\", \"description\": \"issues\"},\\n    {\"source\": \"Traveller\", \"target\": \"Child\", \"type\": \"Composition\", \"description\": \"is-a\"},\\n    {\"source\": \"Traveller\", \"target\": \"Adult\", \"type\": \"Composition\", \"description\": \"is-a\"},\\n    {\"source\": \"MetroStation\", \"target\": \"CurrencyNote\", \"type\": \"Association\", \"description\": \"issues\"}\\n  ]\\n}'\n",
      "\n",
      "Relationships Identified:\n",
      " [{'source': 'MetroStation', 'target': 'TicketDistributor', 'type': 'Association', 'description': 'issues'}, {'source': 'Traveller', 'target': 'Passenger', 'type': 'Aggregation', 'description': 'contains'}, {'source': 'User', 'target': 'Transaction', 'type': 'Association', 'description': 'issues'}, {'source': 'Machine', 'target': 'DisplayInterface', 'type': 'Aggregation', 'description': 'contains'}, {'source': 'PaymentMethod', 'target': 'Smartcard', 'type': 'Composition', 'description': 'is-a'}, {'source': 'MetroPass', 'target': 'TimeCard', 'type': 'Aggregation', 'description': 'contains'}, {'source': 'TicketDistributor', 'target': 'User', 'type': 'Association', 'description': 'issues'}, {'source': 'Traveller', 'target': 'Child', 'type': 'Composition', 'description': 'is-a'}, {'source': 'Traveller', 'target': 'Adult', 'type': 'Composition', 'description': 'is-a'}, {'source': 'MetroStation', 'target': 'CurrencyNote', 'type': 'Association', 'description': 'issues'}]\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "\n",
    "def identify_relationships(problem_statement, classes, attributes):\n",
    "    \"\"\"\n",
    "    Identifies relationships between extracted classes using Ollama LLaMA 3.2.\n",
    "    Extracts Association, Generalization (Inheritance), Aggregation, and Composition.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert software analyst. Your task is to identify **all types of relationships** between the given classes based on the problem statement.\n",
    "\n",
    "    ### **Types of Relationships:**\n",
    "    1️⃣ **Association** - One class interacts with another. Example: \"User borrows Book\".\n",
    "    2️⃣ **Generalization (Inheritance)** - One class is a specialized form of another. Example: \"Admin is a subclass of User\".\n",
    "    3️⃣ **Aggregation** - One class is made up of another, but they have independent lifecycles. Example: \"Library has Books, but Books exist independently\".\n",
    "    4️⃣ **Composition** - A stronger form of Aggregation, where the part **cannot exist** without the whole. Example: \"House has Rooms, Rooms cannot exist without a House\".\n",
    "\n",
    "    ### **Rules:**\n",
    "    ✅ Identify the **verbs** and **context clues** in the problem statement to find relationships.  \n",
    "    ✅ Classify the relationship into one of the four types above.  \n",
    "    ✅ **Use clear operation-style descriptions** instead of full sentences.  \n",
    "    ✅ Try to cover **all identified classes** and **attributes** in the relationships.  \n",
    "\n",
    "    ### **Follow this Step-by-Step Approach:**\n",
    "    1. Carefully analyze the problem statement to extract interaction patterns between classes.\n",
    "    2. Identify the type of relationship (Association, Generalization, Aggregation, or Composition).\n",
    "    3. Formulate a short, clear description using an **operation-style** phrase like \"issues\", \"contains\", \"inherits\", etc.\n",
    "    4. Ensure that every identified class is considered for possible relationships.\n",
    "\n",
    "    ### **Output Format:**\n",
    "    Output **ONLY valid JSON** without any explanation:\n",
    "    ```json\n",
    "    {{\n",
    "        \"relationships\": [\n",
    "            {{\"source\": \"ClassA\", \"target\": \"ClassB\", \"type\": \"Association\", \"description\": \"issues\"}},\n",
    "            {{\"source\": \"ClassC\", \"target\": \"ClassD\", \"type\": \"Aggregation\", \"description\": \"contains\"}},\n",
    "            {{\"source\": \"ClassE\", \"target\": \"ClassF\", \"type\": \"Generalization\", \"description\": \"inherits\"}}\n",
    "        ]\n",
    "    }}\n",
    "    ```\n",
    "\n",
    "    ### **Classes Identified:**\n",
    "    {classes}\n",
    "\n",
    "    ### **Attributes Identified:**\n",
    "    {attributes}\n",
    "\n",
    "    ### **Problem Statement:**\n",
    "    {problem_statement}\n",
    "\n",
    "    Now extract **all types of relationships** between the classes.  \n",
    "    **Do NOT include any explanation — output JSON only.**\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate response using Ollama LLaMA 3.2\n",
    "    response = ollama.chat(\n",
    "        model=\"llama3.2\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        options={\n",
    "            \"temperature\": 0,\n",
    "            \"top_p\": 1,\n",
    "            \"top_k\": 1\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ✅ Debugging: Print raw response\n",
    "    response_text = response['message']['content'].strip()\n",
    "    print(\"Raw Response from LLaMA 3.2:\\n\", response_text)\n",
    "\n",
    "    # ✅ Extract JSON part only using regex\n",
    "    json_match = re.search(r\"\\{.*\\}\", response_text, re.DOTALL)\n",
    "    if json_match:\n",
    "        cleaned_text = json_match.group(0).strip()\n",
    "    else:\n",
    "        print(\"Error: No valid JSON found in response.\")\n",
    "        return {}\n",
    "\n",
    "    # ✅ Additional Debugging: Print cleaned text before parsing\n",
    "    print(\"Cleaned JSON:\\n\", repr(cleaned_text))\n",
    "\n",
    "    # ✅ Check if cleaned_text is empty\n",
    "    if not cleaned_text:\n",
    "        print(\"Error: Cleaned JSON is empty. Cannot parse.\")\n",
    "        return {}\n",
    "\n",
    "    # ✅ Parse JSON safely\n",
    "    try:\n",
    "        output = json.loads(cleaned_text)  # Convert string to JSON\n",
    "        return output.get(\"relationships\", [])  # Extract relationships list\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"JSON parsing error:\", str(e))\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Example usage\n",
    "identified_relationships = identify_relationships(problem_statement, identified_classes, identified_attributes)\n",
    "\n",
    "print(\"\\nRelationships Identified:\\n\", identified_relationships)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
