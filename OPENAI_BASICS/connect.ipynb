{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a simple request to OpenAI\n",
    "completion = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are my co-requirement analyst.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How we can extract goals and actors from the given problem in requirements.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ollama model = llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-ollama in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-ollama) (0.4.7)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-ollama) (0.3.43)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (9.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.10.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.3.4)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (6.0.1)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ollama<1,>=0.4.4->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (2023.7.22)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (4.8.0)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (3.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.31.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.10.15)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.27.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# using ollama\n",
    "%pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To answer your question, \"LangChain\" is a web development framework designed for building decentralized applications (dApps) on the blockchain. It provides a set of libraries and tools to simplify the process of creating and deploying smart contracts.\\n\\nHere\\'s a breakdown of LangChain:\\n\\n1. **Decentralized Architecture**: LangChain is built on top of existing blockchain networks, such as Ethereum, Solana, or Polygon. This allows developers to focus on building their dApps without worrying about the underlying infrastructure.\\n2. **Smart Contract Library**: The framework includes a comprehensive library of smart contracts that can be used for various use cases, including data storage, transactions, and more.\\n3. **Decentralized Data Storage**: LangChain provides decentralized data storage solutions using protocols like InterPlanetary File System (IPFS) or Swarm.\\n4. **Web3 Integration**: The framework is designed to work seamlessly with web3 libraries and tools, making it easy for developers to integrate blockchain functionality into their applications.\\n5. **Customization and Flexibility**: LangChain allows developers to customize and extend the framework to fit specific use cases and requirements.\\n\\nOverall, LangChain aims to simplify the development process of decentralized applications by providing a set of pre-built components and tools that can be easily integrated into existing projects or used as a starting point for new dApp development.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cohere_api = os.getenv(\"CO_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# from langchain_cohere.llms import Cohere\n",
    "\n",
    "# llm = Cohere()\n",
    "# print(llm.invoke(\"Come up with a pet name\"))\n",
    "\n",
    "import cohere\n",
    "\n",
    "co = cohere.ClientV2()\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello World!\"}],\n",
    ")\n",
    "\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "GEMINI_API = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Verse 1)\n",
      "In the realm of code, where logic flows,\n",
      "Let's sing a Python song, as our rhythm grows.\n",
      "With indents deep and variables galore,\n",
      "We'll create melodies that we'll forever adore.\n",
      "\n",
      "(Chorus)\n",
      "Oh, Python, Python, our language so grand,\n",
      "You make coding a breeze, with a helping hand.\n",
      "From data science to web design,\n",
      "You're the tool we need, to make our dreams align.\n",
      "\n",
      "(Verse 2)\n",
      "With lists and tuples, we'll store our data,\n",
      "Dictionaries hold keys, and none is our mantra.\n",
      "Functions and classes, oh how they shine,\n",
      "Encapsulating code, making it divine.\n",
      "\n",
      "(Chorus)\n",
      "Oh, Python, Python, our language so grand,\n",
      "You make coding a breeze, with a helping hand.\n",
      "From data science to web design,\n",
      "You're the tool we need, to make our dreams align.\n",
      "\n",
      "(Bridge)\n",
      "From loops to comprehensions, we've got it all,\n",
      "Python's power, we'll never let it fall.\n",
      "With modules and packages, we'll extend our reach,\n",
      "Building applications that will fulfill our speech.\n",
      "\n",
      "(Verse 3)\n",
      "With algorithms and data structures in sight,\n",
      "We'll solve problems complex, day and night.\n",
      "Object-oriented programming, a concept so true,\n",
      "Encapsulation, inheritance, and polymorphism, we'll pursue.\n",
      "\n",
      "(Chorus)\n",
      "Oh, Python, Python, our language so grand,\n",
      "You make coding a breeze, with a helping hand.\n",
      "From data science to web design,\n",
      "You're the tool we need, to make our dreams align.\n",
      "\n",
      "(Outro)\n",
      "So let's raise our voices, and sing this song,\n",
      "To Python, the language, where we truly belong.\n",
      "May its power inspire, and its elegance guide,\n",
      "As we journey together, side by side.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key=GEMINI_API)\n",
    "response = llm.invoke(\"give me python song that i can sing with u\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ollama model = deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-ollama in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-ollama) (0.3.43)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-ollama) (0.4.7)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (6.0.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.3.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.10.6)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ollama<1,>=0.4.4->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (2023.7.22)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.31.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.10.15)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.23.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain-ollama) (2.0.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain-ollama) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "I need to determine how many additional cars will be in the parking lot after 2 more arrive.\n",
      "\n",
      "First, I know there are initially 3 cars in the parking lot.\n",
      "\n",
      "Next, I consider the number of cars that will arrive: 2 more cars.\n",
      "\n",
      "Finally, I calculate the total number of cars by adding the initial number and the number arriving.\n",
      "</think>\n",
      "\n",
      "Sure! Let's break down the problem step by step.\n",
      "\n",
      "**Problem Statement:**\n",
      "If there are **3 cars** in the parking lot and **2 more cars** arrive, how many cars are in the parking lot?\n",
      "\n",
      "**Solution:**\n",
      "\n",
      "1. **Initial Number of Cars:**  \n",
      "   There are 3 cars initially in the parking lot.\n",
      "\n",
      "2. **Number of Cars Arriving:**  \n",
      "   2 more cars will arrive at the parking lot.\n",
      "\n",
      "3. **Total Number of Cars After Arrivals:**  \n",
      "   To find the total number of cars after the arrivals, add the initial number to the number of cars arriving:  \n",
      "   \\[\n",
      "   3 \\text{ cars} + 2 \\text{ cars} = 5 \\text{ cars}\n",
      "   \\]\n",
      "\n",
      "**Final Answer:**\n",
      "\\boxed{5}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "question=\"\"\"\n",
    "    Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, therewill be 21 trees. How many trees did the grove workers plant today?\n",
    "    A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have\n",
    "    been 21 - 15 = 6. The answer is 6.\n",
    "    Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = OllamaLLM(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "response=chain.invoke({\"question\": question})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
